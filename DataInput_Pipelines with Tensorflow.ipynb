{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataInput_Pipelines.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMKlZ+Lb9P3s1JruktxFByh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhavbaswal95/ComputerVision/blob/master/DataInput_Pipelines%20with%20Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8VFq3MQZsSX",
        "colab_type": "text"
      },
      "source": [
        "## tf.data API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mplaSKchXmx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.data API enables us to build complex input pipelines from simple, reusable pieces.\n",
        "\n",
        "# For example, the pipeline for an image model might aggregate data from files in a distributed file system,\n",
        "# apply random perturbations to each image, and merge randomly selected images into a batch for training. \n",
        "\n",
        "# The pipeline for a text model might involve extracting symbols from raw text data, converting them to embedding \n",
        "# identifiers with a lookup table, and batching together sequences of different lengths."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WE6Sy83ZoKR",
        "colab_type": "text"
      },
      "source": [
        "## tf.data.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXZLcS-kZVuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The tf.data API introduces a tf.data.Dataset abstraction that represents a sequence of elements, in which each element consists of one or more components.\n",
        "\n",
        "# For example, in an image pipeline, an element might be a single training example, with a pair of tensor components representing the image and its label."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcYU2KgYZga9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# There are two distinct ways to create a dataset:\n",
        "\n",
        "# A data source constructs a Dataset from data stored in memory or in one or more files.\n",
        "# A data transformation constructs a dataset from one or more tf.data.Dataset objects."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g__dHjdZmfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# few import for python future functionality\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4B7Bm4OaFgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.enable_eager_execution() #important for getting results instantaneously\n",
        "\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(precision=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3jXwLhkaKBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating input pipeline from data sources\n",
        "# from_tensors()\n",
        "# from_tensor_slices()\n",
        "# TFRecordDataset()\n",
        "\n",
        "# Once you have a Dataset object, you can transform it into a new Dataset by chaining method calls on the tf.data.Dataset object.\n",
        "# For example, you can apply per-element transformations such as Dataset.map(), and multi-element transformations such as Dataset.batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dskDaWJEayTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a592833b-7a48-4778-f1cc-6d8d231e085e"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])\n",
        "dataset"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFGbsCOOazn2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "332a843c-53ce-4a7e-f5dc-2da92457f623"
      },
      "source": [
        "# The Dataset object is a Python iterable. This makes it possible to consume its elements using a for loop:\n",
        "\n",
        "for elem in dataset:\n",
        "  print(elem.numpy())"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "3\n",
            "0\n",
            "8\n",
            "2\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsOPV9PNa3p_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79d88206-e819-460e-8be1-e8191877b203"
      },
      "source": [
        "# creating a Python iterator using iter and consuming its elements using next\n",
        "it = iter(dataset)\n",
        "print(next(it).numpy())"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZkH5kkebE69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "c17ec5bd-b9f5-4050-81cb-f6f12241ac93"
      },
      "source": [
        "# Alternatively, dataset elements can be consumed using the reduce transformation, which reduces all elements to produce a single result.\n",
        "\n",
        "for i in dataset:\n",
        "  print(i.numpy())\n"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "3\n",
            "0\n",
            "8\n",
            "2\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq3IrD8HciXf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20c63e9c-be44-4344-d801-cea80b69865b"
      },
      "source": [
        "print(dataset.reduce(0, lambda state, value : state + value).numpy())\n",
        "\n",
        "# 0 is the initial state \n",
        "# lambda function takes 2 argument old_state and new element to return new state "
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vszMXzYmiHb1",
        "colab_type": "text"
      },
      "source": [
        "# Dataset **Structure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbTk3NsScz6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # A dataset contains elements that each have the same (nested) structure and the individual components of the structure can be of any type representable by\n",
        "# # tf.TypeSpec, including Tensor, SparseTensor, RaggedTensor, TensorArray, or Dataset.\n",
        "\n",
        "# The Dataset.element_spec property allows you to inspect the type of each element component. The property returns a nested structure of tf.TypeSpec objects,\n",
        "#  matching the structure of the element, \n",
        "#  which may be a single component, \n",
        "#  a tuple of components, \n",
        "#  or a nested tuple of components. \n",
        " \n",
        "#  For example:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlfDqhCMi8Lk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cd642bf-9c6b-4cde-8a4e-13d014815a2d"
      },
      "source": [
        "tf.random.uniform([4]) # tensor with 4 elements picked randomly from uniform distribution"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=54399, shape=(4,), dtype=float32, numpy=array([0.5189, 0.1423, 0.0793, 0.0326], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmG63vFejBOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ddf26ee-fda0-4b1a-8588-a46a62bcb092"
      },
      "source": [
        "tf.random.uniform([4,100]) # tensor with 4 elements with 100 elements in each, picked randomly from uniform distribution"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=54406, shape=(4, 100), dtype=float32, numpy=\n",
              "array([[2.6000e-01, 7.0136e-01, 9.3297e-01, 6.1512e-01, 9.6711e-01,\n",
              "        9.1897e-01, 5.0030e-03, 5.2029e-01, 4.9330e-01, 6.7616e-01,\n",
              "        3.2295e-01, 1.9213e-01, 1.4459e-01, 8.5800e-01, 4.3934e-01,\n",
              "        7.8393e-01, 8.9524e-01, 6.9418e-01, 9.8573e-01, 8.2910e-01,\n",
              "        1.7645e-01, 8.2130e-01, 1.6727e-01, 1.8965e-02, 2.2085e-03,\n",
              "        1.2577e-01, 3.3763e-01, 3.2875e-01, 2.4778e-01, 3.7950e-01,\n",
              "        5.3768e-01, 2.0966e-02, 5.5340e-01, 2.1140e-01, 9.2948e-01,\n",
              "        2.9901e-01, 9.3281e-01, 7.1184e-01, 2.5234e-01, 5.3230e-01,\n",
              "        1.9655e-01, 6.4796e-01, 7.9475e-01, 2.1970e-01, 7.2693e-01,\n",
              "        6.3158e-01, 9.0722e-01, 6.2177e-01, 1.0747e-02, 8.5942e-01,\n",
              "        3.2445e-01, 7.3720e-01, 5.5915e-02, 2.1608e-01, 7.2705e-01,\n",
              "        8.9620e-01, 4.1577e-01, 5.9589e-01, 8.6361e-01, 3.2141e-01,\n",
              "        6.9932e-01, 1.2920e-01, 2.6142e-01, 6.8537e-01, 1.6269e-01,\n",
              "        3.8085e-01, 1.8124e-01, 1.0200e-01, 6.0669e-01, 5.5147e-01,\n",
              "        4.0984e-01, 6.0234e-01, 5.5670e-03, 2.5380e-01, 8.6401e-01,\n",
              "        8.1832e-01, 2.1745e-01, 3.4009e-01, 7.0311e-01, 7.0349e-02,\n",
              "        9.8760e-01, 7.3293e-02, 6.5076e-01, 3.8392e-01, 7.0295e-01,\n",
              "        7.5970e-01, 4.0778e-01, 3.5647e-01, 3.0702e-01, 7.8534e-01,\n",
              "        5.0880e-01, 5.0809e-01, 4.1168e-01, 5.8119e-02, 2.7540e-02,\n",
              "        9.6641e-01, 4.5553e-01, 2.1136e-01, 8.6966e-01, 7.5458e-01],\n",
              "       [9.2357e-01, 8.5494e-01, 6.1575e-01, 7.5463e-01, 8.1036e-01,\n",
              "        1.4281e-01, 4.8147e-01, 6.7328e-01, 7.2048e-01, 9.6934e-01,\n",
              "        7.2140e-01, 4.7276e-01, 4.8214e-02, 8.1970e-01, 9.6425e-01,\n",
              "        1.3885e-02, 3.4072e-01, 5.0838e-01, 5.5973e-01, 3.7557e-01,\n",
              "        7.1950e-01, 7.4991e-01, 1.4170e-01, 8.2588e-01, 4.0561e-01,\n",
              "        4.4677e-01, 9.7837e-02, 1.8536e-01, 6.6552e-01, 9.6272e-01,\n",
              "        6.8340e-01, 3.2947e-01, 3.1477e-01, 9.8562e-01, 5.3944e-01,\n",
              "        9.3343e-01, 2.6193e-01, 6.1750e-01, 1.6014e-01, 1.7570e-01,\n",
              "        6.8802e-01, 5.0994e-01, 3.4127e-01, 7.2222e-01, 5.6721e-01,\n",
              "        6.4909e-01, 2.9616e-01, 1.1610e-01, 7.7003e-01, 3.1646e-02,\n",
              "        8.8044e-01, 1.6107e-01, 6.2748e-01, 3.7985e-01, 3.1027e-01,\n",
              "        6.7650e-01, 8.9963e-01, 2.2910e-01, 6.6391e-01, 6.3218e-01,\n",
              "        3.1145e-02, 2.2785e-01, 7.3354e-01, 2.8147e-01, 1.6334e-01,\n",
              "        5.1478e-01, 1.3696e-01, 1.0422e-01, 9.6295e-01, 6.0452e-01,\n",
              "        7.8084e-01, 7.7271e-01, 8.9331e-01, 1.5106e-01, 6.4176e-01,\n",
              "        9.3015e-01, 6.4960e-01, 8.7677e-01, 2.8633e-01, 1.6401e-02,\n",
              "        2.0975e-01, 2.4818e-01, 9.4832e-03, 1.1188e-01, 2.5262e-01,\n",
              "        5.3984e-01, 1.9402e-01, 7.8981e-01, 2.9905e-01, 8.1390e-01,\n",
              "        4.1424e-02, 6.3668e-01, 3.1608e-01, 9.1992e-01, 4.5207e-01,\n",
              "        9.2146e-01, 2.4736e-01, 9.6397e-01, 4.9755e-01, 5.9793e-01],\n",
              "       [8.7339e-01, 1.0507e-01, 7.5629e-01, 7.9377e-01, 3.3698e-01,\n",
              "        7.0956e-01, 7.4244e-01, 2.3968e-01, 6.9326e-01, 3.8785e-01,\n",
              "        6.6912e-01, 2.8873e-01, 5.8859e-01, 3.8935e-01, 6.2654e-01,\n",
              "        9.1481e-01, 6.9852e-01, 7.2214e-01, 9.7924e-01, 6.5861e-01,\n",
              "        7.6046e-01, 7.2698e-01, 2.5163e-01, 6.5996e-01, 6.3596e-01,\n",
              "        2.7348e-01, 7.0835e-01, 6.2962e-01, 1.2515e-01, 2.2892e-02,\n",
              "        5.1775e-01, 5.9495e-01, 2.4455e-01, 9.1756e-01, 9.1341e-01,\n",
              "        5.1312e-02, 6.6541e-01, 4.3902e-02, 5.3695e-01, 9.6600e-01,\n",
              "        1.7955e-01, 5.7247e-01, 4.6140e-01, 9.9154e-01, 3.1763e-01,\n",
              "        1.1335e-01, 1.4840e-01, 6.5965e-01, 1.4276e-01, 3.4889e-01,\n",
              "        5.8461e-01, 2.3270e-01, 3.7928e-01, 9.9105e-01, 2.7513e-01,\n",
              "        8.1319e-01, 7.6382e-01, 6.8550e-01, 3.4475e-01, 7.8304e-01,\n",
              "        4.2585e-01, 6.8375e-01, 1.6686e-01, 7.3431e-03, 3.2783e-01,\n",
              "        4.2757e-01, 2.7949e-01, 9.6723e-01, 1.5389e-01, 7.8555e-01,\n",
              "        1.5597e-01, 8.4285e-01, 7.8653e-01, 1.1587e-01, 3.1994e-01,\n",
              "        4.8822e-01, 7.4601e-01, 3.2425e-01, 2.9714e-01, 7.7722e-01,\n",
              "        1.4151e-01, 6.1010e-01, 5.4486e-01, 3.2745e-01, 6.8490e-01,\n",
              "        8.2163e-01, 6.7122e-01, 2.2850e-01, 8.9792e-01, 3.2739e-02,\n",
              "        9.5860e-01, 9.4333e-01, 9.8527e-01, 2.5688e-02, 9.7701e-01,\n",
              "        5.4913e-01, 9.6418e-02, 7.2150e-01, 5.2547e-01, 6.8605e-04],\n",
              "       [7.0087e-01, 4.3515e-01, 9.6605e-01, 6.8730e-01, 1.6382e-01,\n",
              "        1.2222e-02, 5.1048e-01, 4.9317e-01, 2.7759e-01, 7.9767e-01,\n",
              "        9.4750e-01, 2.2039e-01, 7.4355e-01, 4.8139e-01, 5.5657e-01,\n",
              "        2.6869e-01, 1.6797e-01, 5.2971e-01, 1.9018e-01, 2.1371e-01,\n",
              "        7.2104e-01, 9.3795e-01, 1.4877e-01, 7.8565e-01, 4.2918e-01,\n",
              "        7.9342e-01, 3.8354e-01, 1.8763e-01, 7.0030e-01, 2.5723e-01,\n",
              "        4.4117e-03, 6.8712e-01, 6.3921e-01, 6.4399e-02, 7.2603e-01,\n",
              "        7.8122e-01, 5.0687e-01, 6.6632e-01, 3.5123e-01, 9.3828e-01,\n",
              "        6.0820e-01, 7.4031e-02, 3.3529e-01, 7.4514e-01, 9.9875e-01,\n",
              "        2.2320e-01, 5.1550e-01, 9.9857e-02, 7.0599e-01, 5.8673e-01,\n",
              "        7.6961e-02, 5.9778e-01, 1.4513e-01, 5.7763e-01, 4.3031e-01,\n",
              "        5.7388e-01, 3.3194e-01, 1.0749e-01, 3.3383e-01, 5.8780e-01,\n",
              "        3.2611e-01, 4.2925e-01, 7.3770e-01, 3.0884e-01, 4.9507e-01,\n",
              "        4.0350e-01, 6.7375e-01, 7.5949e-01, 9.1625e-01, 8.7808e-02,\n",
              "        6.8915e-01, 5.4680e-01, 7.5161e-01, 4.6625e-01, 4.9019e-01,\n",
              "        6.6725e-01, 4.5573e-01, 8.7827e-01, 9.9479e-01, 8.2766e-01,\n",
              "        9.9687e-01, 8.6237e-01, 7.2847e-01, 7.0521e-03, 8.5646e-01,\n",
              "        6.0621e-01, 5.8508e-01, 2.2727e-01, 3.5129e-01, 3.5341e-01,\n",
              "        8.6976e-02, 3.4658e-01, 7.2802e-01, 3.1237e-01, 4.5382e-01,\n",
              "        9.7205e-01, 7.3397e-01, 6.0494e-01, 8.1813e-01, 9.6239e-01]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYHEtfsJiTYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa64f060-2f77-4b62-b5cb-b710744147be"
      },
      "source": [
        "# dataset from tensor\n",
        "dataset1 = tf.data.Dataset.from_tensor_slices(tf.random.uniform([4, 10]))\n",
        "\n",
        "dataset1.element_spec"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorSpec(shape=(10,), dtype=tf.float32, name=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a63XzXSsi2c2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c387edc8-e88a-471f-989d-47e8fa3eabb0"
      },
      "source": [
        "# dataset from many tensors\n",
        "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
        "   (tf.random.uniform([4]),\n",
        "    tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)))\n",
        "\n",
        "dataset2.element_spec"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(100,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UKKj6ITjII0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "86cd3627-255b-4e98-d3fd-84689cbeba70"
      },
      "source": [
        "# combining together\n",
        "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
        "\n",
        "dataset3.element_spec"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(10,), dtype=tf.float32, name=None),\n",
              " (TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
              "  TensorSpec(shape=(100,), dtype=tf.int32, name=None)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj6kVwTxkAM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cd5c576-0f5c-43dc-dfd1-681c5513fb14"
      },
      "source": [
        "tf.SparseTensor(indices=[[0,0],[1,2]], values=[1,2], dense_shape=[3,4])\n",
        "# SparseTensor"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7fa74d3e3978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sbsmSaajnL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c75da8ce-d291-4248-c074-b024cc0ffc84"
      },
      "source": [
        "# Dataset containing a sparse tensor.\n",
        "dataset4 = tf.data.Dataset.from_tensors(tf.SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4]))\n",
        "\n",
        "dataset4.element_spec"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseTensorSpec(TensorShape([Dimension(3), Dimension(4)]), tf.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioKUOiL8nEo0",
        "colab_type": "text"
      },
      "source": [
        "## Dataset **Transformations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqf8O9pUj_lP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e477500-8f7d-421e-a921-b0f819ddc918"
      },
      "source": [
        "# The Dataset transformations support datasets of any structure. \n",
        "# When using the Dataset.map(), and Dataset.filter() transformations, which apply a function to each element, the element structure determines the arguments of the function:\n",
        "\n",
        "dataset1 = tf.data.Dataset.from_tensor_slices(\n",
        "    tf.random.uniform([4, 10], minval=1, maxval=10, dtype=tf.int32))\n",
        "\n",
        "dataset1"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: (10,), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ODe-oMwm-Ux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "72eccbe7-a964-4454-b827-f1c051758dcc"
      },
      "source": [
        "for z in dataset1:\n",
        "  print(z.numpy())"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 4 9 4 1 5 3 3 8 6]\n",
            "[9 1 8 8 5 5 2 6 3 7]\n",
            "[5 6 3 8 5 8 8 4 6 5]\n",
            "[4 5 9 8 3 5 7 4 9 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soYd50jUnC01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ab8bc7d-d484-4957-c216-0e057fd9e721"
      },
      "source": [
        "dataset2 = tf.data.Dataset.from_tensor_slices(\n",
        "   (tf.random.uniform([4]),\n",
        "    tf.random.uniform([4, 100], maxval=100, dtype=tf.int32)))\n",
        "\n",
        "dataset2"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((), (100,)), types: (tf.float32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7inLufYpnpen",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6efc33d-3a92-488f-8def-dd3d6e718dec"
      },
      "source": [
        "dataset3 = tf.data.Dataset.zip((dataset1, dataset2))\n",
        "\n",
        "dataset3"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((10,), ((), (100,))), types: (tf.int32, (tf.float32, tf.int32))>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvEgCy5nnr-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "eb39a350-a00e-4094-fcae-38ea46009dec"
      },
      "source": [
        "for a, (b,c) in dataset3:\n",
        "  print('shapes: {a.shape}, {b.shape}, {c.shape}'.format(a=a, b=b, c=c))"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shapes: (10,), (), (100,)\n",
            "shapes: (10,), (), (100,)\n",
            "shapes: (10,), (), (100,)\n",
            "shapes: (10,), (), (100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqnkSr9SzUV5",
        "colab_type": "text"
      },
      "source": [
        "# Reading **input** data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8yUlr_2y1lL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If all of your input data fits in memory, the simplest way to create a Dataset from them is to convert them to tf.Tensor objects \n",
        "# use Dataset.from_tensor_slices()\n",
        "\n",
        "train, test = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neHOIGwfzXed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f54131f4-e4ce-4855-a912-21b197370625"
      },
      "source": [
        "images, labels = train\n",
        "images = images/255\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "dataset"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((28, 28), ()), types: (tf.float64, tf.uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic4DBIE8EdXb",
        "colab_type": "text"
      },
      "source": [
        "# Consuming Python **Generators**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2jqXOwFztL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Consuming Python generators\n",
        "# Another common data source that can easily be ingested as a tf.data.Dataset is the python generator.\n",
        "\n",
        "def count(stop):\n",
        "  i = 0\n",
        "  while i<stop:\n",
        "    yield i\n",
        "    i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLuAWKv2z1tL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "0fd2705b-95e4-4df5-e3d7-219b1c0b084a"
      },
      "source": [
        "for n in count(5):\n",
        "  print(n)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LKSwnKBz25C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Dataset.from_generator constructor converts the python generator to a fully functional tf.data.Dataset.\n",
        "ds_counter = tf.data.Dataset.from_generator(count, args = [25], output_types=tf.int32, output_shapes=(),)\n",
        "\n",
        "# The constructor takes a callable as input, not an iterator. This allows it to restart the generator when it reaches the end. \n",
        "# It takes an optional args argument, which is passed as the callable's arguments.\n",
        "\n",
        "# The output_types argument is required because tf.data builds a tf.Graph internally, and graph edges require a tf.dtype."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GnnSCQO0apl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "582344cd-e822-4835-844a-0815a3e2d563"
      },
      "source": [
        "for count_batch in ds_counter.repeat().batch(10).take(5):\n",
        "  print(count_batch.numpy())"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "[10 11 12 13 14 15 16 17 18 19]\n",
            "[20 21 22 23 24  0  1  2  3  4]\n",
            "[ 5  6  7  8  9 10 11 12 13 14]\n",
            "[15 16 17 18 19 20 21 22 23 24]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HsNO7Q70wX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The output_shapes argument is not required but is highly recomended as many tensorflow operations do not support tensors with unknown rank. \n",
        "# If the length of a particular axis is unknown or variable, set it as None in the output_shapes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaURZhZ01Oz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here is an example generator that demonstrates both aspects, it returns tuples of arrays, where the second array is a vector with unknown length\n",
        "def gen_series():\n",
        "  i = 0\n",
        "  while True:\n",
        "    size = np.random.randint(0, 10)\n",
        "    yield i, np.random.normal(size=(size,))\n",
        "    i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eHlJwgE1aTn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "efa3e133-8b1d-4268-ca20-12779af377af"
      },
      "source": [
        "for i, series in gen_series():\n",
        "  print(i, \":\", str(series))\n",
        "  if i > 5:\n",
        "    break"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 : [ 0.3295  1.4132  0.0534  0.7677 -0.0115 -0.2631]\n",
            "1 : []\n",
            "2 : [1.8892 0.2117 0.5582]\n",
            "3 : [ 0.3612  0.5921 -0.1273 -1.2374  0.1988 -1.445   1.6463 -0.3292  0.6723]\n",
            "4 : []\n",
            "5 : [-1.1839 -1.1007 -1.296  -0.4785  0.3676 -1.0314  0.3547 -1.4683]\n",
            "6 : [-0.5354  0.3232 -0.1999 -1.5655]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4WxucAr1tD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "c3bc9a00-2ac3-4b51-e550-7c3d8b55b828"
      },
      "source": [
        "for i,s in gen_series():\n",
        "  print(type(i),\":\",type(s))\n",
        "  if i>5:\n",
        "    break"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'int'> : <class 'numpy.ndarray'>\n",
            "<class 'int'> : <class 'numpy.ndarray'>\n",
            "<class 'int'> : <class 'numpy.ndarray'>\n",
            "<class 'int'> : <class 'numpy.ndarray'>\n",
            "<class 'int'> : <class 'numpy.ndarray'>\n",
            "<class 'int'> : <class 'numpy.ndarray'>\n",
            "<class 'int'> : <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaG8-hj_2Rn_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "425cd7e5-1ebd-42f3-acc5-52eb25990d25"
      },
      "source": [
        "ds_series = tf.data.Dataset.from_generator(\n",
        "    gen_series, \n",
        "    output_types=(tf.int32, tf.float32), \n",
        "    output_shapes=((), (None,)))\n",
        "\n",
        "ds_series"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((), (?,)), types: (tf.int32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXLADnh76nQk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "a9078327-4947-468f-f5f1-9c6f756ab2bf"
      },
      "source": [
        "for (i,j) in ds_series:\n",
        "  print(i,j)\n",
        "  i += 1\n",
        "  if i.numpy() > 5:\n",
        "    break\n"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32) tf.Tensor([ 0.9216 -1.0667 -0.513   0.4258 -0.3533  1.59  ], shape=(6,), dtype=float32)\n",
            "tf.Tensor(1, shape=(), dtype=int32) tf.Tensor([ 1.9053 -0.3863 -0.2576 -0.5493], shape=(4,), dtype=float32)\n",
            "tf.Tensor(2, shape=(), dtype=int32) tf.Tensor([ 1.6094  1.0931  0.3305 -0.083   1.217   0.5942], shape=(6,), dtype=float32)\n",
            "tf.Tensor(3, shape=(), dtype=int32) tf.Tensor([ 0.3737 -1.7276  0.1943  1.4043 -0.3213  0.09   -0.4149 -0.0825], shape=(8,), dtype=float32)\n",
            "tf.Tensor(4, shape=(), dtype=int32) tf.Tensor([ 1.9798  0.7006 -0.1994  0.1067 -0.89    0.3898  0.8002  0.2242], shape=(8,), dtype=float32)\n",
            "tf.Tensor(5, shape=(), dtype=int32) tf.Tensor([-1.0003  0.1941 -1.4914], shape=(3,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaYcAQ5X8nhp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "587be03b-85a7-4b7a-99f2-0d962f075d3c"
      },
      "source": [
        "ds_series.element_spec"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.int32, name=None),\n",
              " TensorSpec(shape=(?,), dtype=tf.float32, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01s40Gxg9CFO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "71a2f5fc-94a1-4da6-b643-fcc3a08cb310"
      },
      "source": [
        "ds_series_batch = ds_series.shuffle(20).padded_batch(batch_size=10,padded_shapes=([],[10,]))\n",
        "\n",
        "ids, sequence_batch = next(iter(ds_series_batch))\n",
        "print(ids.numpy())\n",
        "print()\n",
        "print(sequence_batch.numpy())"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17  5 12 11 21  9  4 22 19 26]\n",
            "\n",
            "[[ 1.7809e+00  2.4111e+00 -8.9688e-01  5.1726e-01  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00]\n",
            " [-1.7194e+00  2.7396e-01  2.4720e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00]\n",
            " [-2.0499e+00 -1.7956e+00 -4.1560e-01  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00]\n",
            " [ 2.1430e+00  9.7250e-01  8.6747e-01 -6.8606e-01 -1.1640e+00  1.4149e-01\n",
            "  -4.8939e-01 -4.7391e-02  0.0000e+00  0.0000e+00]\n",
            " [-1.2061e+00  1.1375e+00  7.1115e-01 -1.7961e+00 -4.4770e-01  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00]\n",
            " [ 9.6129e-01  3.4106e-01 -1.3752e-03 -9.0193e-01 -8.4836e-01  1.0217e+00\n",
            "  -1.1765e+00  7.5524e-01  0.0000e+00  0.0000e+00]\n",
            " [ 3.7254e-01  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00]\n",
            " [ 6.0329e-01  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00]\n",
            " [-1.2116e+00  7.6098e-01  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00]\n",
            " [-1.9600e-01 -5.9746e-01 -8.4891e-01  3.2015e-01 -7.6582e-01  0.0000e+00\n",
            "   0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjhq5Q9eAAWC",
        "colab_type": "text"
      },
      "source": [
        "Some **HandsOn** with some **PreProcessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxwBvDm13aUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flowers = tf.keras.utils.get_file(\n",
        "    'flower_photos',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "    untar=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RwNLSu5AA82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, rotation_range=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF8dzjS2AKA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb5d311f-8eda-45ac-d581-561cd30491fc"
      },
      "source": [
        "type(img_gen)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.keras.preprocessing.image.ImageDataGenerator"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMqCDduQAQSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0134dfc1-b06c-4de2-a5d4-368fad7a6ed1"
      },
      "source": [
        "for i,j in img_gen.flow_from_directory(flowers):\n",
        "  print(i.shape,j.shape)\n",
        "  break"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3670 images belonging to 5 classes.\n",
            "(32, 256, 256, 3) (32, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmxHyydFAd-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58827272-2f92-4580-b790-de8ad4a5f124"
      },
      "source": [
        "ds = tf.data.Dataset.from_generator(\n",
        "    img_gen.flow_from_directory, args=[flowers], \n",
        "    output_types=(tf.float32, tf.float32), \n",
        "    output_shapes=([32,256,256,3], [32,5])\n",
        ")\n",
        "\n",
        "ds"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((32, 256, 256, 3), (32, 5)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLT71fT7Ekd1",
        "colab_type": "text"
      },
      "source": [
        "# Consuming **TFRecord** data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXWSkCj-C1-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "66385197-b250-40d8-8117-7ab165eadbd7"
      },
      "source": [
        "# Creates a dataset that reads all of the examples from two files.\n",
        "fsns_test_file = tf.keras.utils.get_file(\"fsns.tfrec\", \"https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001\")"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/fsns-20160927/testdata/fsns-00000-of-00001\n",
            "7905280/7904079 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGWojKuPDezr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "710b4973-4458-4c58-c164-6e622a1d07f5"
      },
      "source": [
        "dataset = tf.data.TFRecordDataset(filenames = [fsns_test_file])\n",
        "dataset"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TFRecordDatasetV1 shapes: (), types: tf.string>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzIRtlytFKkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_example = next(iter(dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiGz9sAvFRZg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "afc1f7c4-7165-4959-f43b-9b0cc7ac8ba1"
      },
      "source": [
        "parsed = tf.train.Example.FromString(raw_example.numpy()) ### what is tf.train.Example, didn't get it\n",
        "\n",
        "parsed.features.feature['image/text']"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bytes_list {\n",
              "  value: \"Rue Perreyon\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnoDNO9MFbF7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04fec7a2-455d-4a3e-ab65-5de01be1c01a"
      },
      "source": [
        "type(raw_example)"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkJg0H2cIXsC",
        "colab_type": "text"
      },
      "source": [
        "# Consuming **text** data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgo90-nAFpxm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "f9d2870c-d6c0-4596-a30a-c2dec23c44f6"
      },
      "source": [
        "directory_url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'\n",
        "file_names = ['cowper.txt', 'derby.txt', 'butler.txt']\n",
        "\n",
        "file_paths = [\n",
        "    tf.keras.utils.get_file(file_name, directory_url + file_name)\n",
        "    for file_name in file_names\n",
        "]"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/cowper.txt\n",
            "819200/815980 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt\n",
            "811008/809730 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt\n",
            "811008/807992 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ8mgfpGK9Le",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7b4b1c4d-9951-4b28-8f69-e0056973eb74"
      },
      "source": [
        "file_paths"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/root/.keras/datasets/cowper.txt',\n",
              " '/root/.keras/datasets/derby.txt',\n",
              " '/root/.keras/datasets/butler.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ_SbTT8LAVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.TextLineDataset(file_paths)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSwKv7eeLDKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "9962cc71-cee5-4322-bffb-081a32037ef2"
      },
      "source": [
        "for line in dataset.take(5):\n",
        "  print(line)"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b\"\\xef\\xbb\\xbfAchilles sing, O Goddess! Peleus' son;\", shape=(), dtype=string)\n",
            "tf.Tensor(b'His wrath pernicious, who ten thousand woes', shape=(), dtype=string)\n",
            "tf.Tensor(b\"Caused to Achaia's host, sent many a soul\", shape=(), dtype=string)\n",
            "tf.Tensor(b'Illustrious into Ades premature,', shape=(), dtype=string)\n",
            "tf.Tensor(b'And Heroes gave (so stood the will of Jove)', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3DaWnieLEdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0dc267b7-3c7d-46f0-bc01-ef2f55145a52"
      },
      "source": [
        "titanic_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
        "titanic_lines = tf.data.TextLineDataset(titanic_file)"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
            "32768/30874 [===============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMXE6V0wLYoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "aa5ceaf6-10d7-4171-8628-79589f7b390c"
      },
      "source": [
        "for line in titanic_lines.take(10):\n",
        "  print(line.numpy())"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone'\n",
            "b'0,male,22.0,1,0,7.25,Third,unknown,Southampton,n'\n",
            "b'1,female,38.0,1,0,71.2833,First,C,Cherbourg,n'\n",
            "b'1,female,26.0,0,0,7.925,Third,unknown,Southampton,y'\n",
            "b'1,female,35.0,1,0,53.1,First,C,Southampton,n'\n",
            "b'0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y'\n",
            "b'0,male,2.0,3,1,21.075,Third,unknown,Southampton,n'\n",
            "b'1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n'\n",
            "b'1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n'\n",
            "b'1,female,4.0,1,1,16.7,Third,G,Southampton,n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE58Eo5tLaPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def survived(line):\n",
        "  return tf.not_equal(tf.strings.substr(line,0,1),'0')\n",
        "\n",
        "survivors = titanic_lines.skip(1).filter(survived)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdV2Gy_iMewo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "f263c30c-43f7-41d7-d5cc-a9eeee3a3325"
      },
      "source": [
        "for line in survivors.take(10):\n",
        "  print(line.numpy())"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'1,female,38.0,1,0,71.2833,First,C,Cherbourg,n'\n",
            "b'1,female,26.0,0,0,7.925,Third,unknown,Southampton,y'\n",
            "b'1,female,35.0,1,0,53.1,First,C,Southampton,n'\n",
            "b'1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n'\n",
            "b'1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n'\n",
            "b'1,female,4.0,1,1,16.7,Third,G,Southampton,n'\n",
            "b'1,male,28.0,0,0,13.0,Second,unknown,Southampton,y'\n",
            "b'1,female,28.0,0,0,7.225,Third,unknown,Cherbourg,y'\n",
            "b'1,male,28.0,0,0,35.5,First,A,Southampton,y'\n",
            "b'1,female,38.0,1,5,31.3875,Third,unknown,Southampton,n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZlC6NL-NjE5",
        "colab_type": "text"
      },
      "source": [
        "# Consuming **CSV** data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFfm-5_ZMj-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}